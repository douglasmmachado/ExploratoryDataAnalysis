{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvECEcoWFNrHn1XaYdwYcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/douglasmmachado/MedicineConsumption/blob/master/notebooks/division_approach/6_Forecasting_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 - Forecasting and prediction validation"
      ],
      "metadata": {
        "id": "_jKlqIUfCkX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3faZHM1dCq8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import math as m\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from subprocess import call\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error,  mean_absolute_percentage_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "df_h1_url =\"https://raw.githubusercontent.com/douglasmmachado/ExploratoryDataAnalysis/agglomerative_clustering/datasets/division_approach/clustered/df_h1_clustered.csv\"\n",
        "df_h2_url =\"https://raw.githubusercontent.com/douglasmmachado/ExploratoryDataAnalysis/agglomerative_clustering/datasets/division_approach/clustered/df_h2_clustered.csv\"\n",
        "df_h3_url =\"https://raw.githubusercontent.com/douglasmmachado/ExploratoryDataAnalysis/agglomerative_clustering/datasets/division_approach/clustered/df_h3_clustered.csv\"\n",
        "df_h4_url =\"https://raw.githubusercontent.com/douglasmmachado/ExploratoryDataAnalysis/agglomerative_clustering/datasets/division_approach/clustered/df_h4_clustered.csv\"\n",
        "\n",
        "\n",
        "\n",
        "df_h1 = pd.read_csv(df_h1_url)\n",
        "df_h1['YEAR'] = df_h1['YEAR'].astype(int)\n",
        "df_h1['MONTH'] = df_h1['MONTH'].astype(int)\n",
        "df_h1['DATE'] = pd.to_datetime(df_h1['YEAR'].astype(str) + '-' + df_h1['MONTH'].astype(str), format='%Y-%m')\n",
        "\n",
        "df_h2 = pd.read_csv(df_h2_url)\n",
        "df_h2['YEAR'] = df_h2['YEAR'].astype(int)\n",
        "df_h2['MONTH'] = df_h2['MONTH'].astype(int)\n",
        "df_h2['DATE'] = pd.to_datetime(df_h2['YEAR'].astype(str) + '-' + df_h2['MONTH'].astype(str), format='%Y-%m')\n",
        "\n",
        "df_h3 = pd.read_csv(df_h3_url)\n",
        "df_h3['YEAR'] = df_h3['YEAR'].astype(int)\n",
        "df_h3['MONTH'] = df_h3['MONTH'].astype(int)\n",
        "df_h3['DATE'] = pd.to_datetime(df_h3['YEAR'].astype(str) + '-' + df_h3['MONTH'].astype(str), format='%Y-%m')\n",
        "\n",
        "df_h4 = pd.read_csv(df_h4_url)\n",
        "df_h4['YEAR'] = df_h4['YEAR'].astype(int)\n",
        "df_h4['MONTH'] = df_h4['MONTH'].astype(int)\n",
        "df_h4['DATE'] = pd.to_datetime(df_h4['YEAR'].astype(str) + '-' + df_h4['MONTH'].astype(str), format='%Y-%m')"
      ],
      "metadata": {
        "id": "R41SXb4cCgUh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_h1.info()"
      ],
      "metadata": {
        "id": "22Vq-PNUZDwu",
        "outputId": "ddba4a14-a98a-4d4c-b263-9895ec0cb3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525 entries, 0 to 524\n",
            "Data columns (total 18 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   CODE_ATC        525 non-null    int64         \n",
            " 1   DATE            525 non-null    datetime64[ns]\n",
            " 2   HOSPI_CODE_UCD  525 non-null    int64         \n",
            " 3   LIT_HC          525 non-null    float64       \n",
            " 4   LIT_HP          525 non-null    float64       \n",
            " 5   MONTH           525 non-null    int64         \n",
            " 6   N_UFS           525 non-null    float64       \n",
            " 7   PN_MEDICAL      525 non-null    float64       \n",
            " 8   POPULATION      525 non-null    float64       \n",
            " 9   P_MEDICAL       525 non-null    float64       \n",
            " 10  QUANTITY        525 non-null    float64       \n",
            " 11  QUANTITY_MA     525 non-null    float64       \n",
            " 12  SEJ_MCO         525 non-null    float64       \n",
            " 13  SEJ_SLD         525 non-null    float64       \n",
            " 14  SEJ_SSR         525 non-null    float64       \n",
            " 15  WEEK            525 non-null    int64         \n",
            " 16  YEAR            525 non-null    int64         \n",
            " 17  CLUSTER         525 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(11), int64(6)\n",
            "memory usage: 74.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_h2.info()"
      ],
      "metadata": {
        "id": "kQ3pF2FVZD4C",
        "outputId": "7a66df38-841f-4f61-aa98-1c1dbd1f2f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525 entries, 0 to 524\n",
            "Data columns (total 18 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   CODE_ATC        525 non-null    int64         \n",
            " 1   DATE            525 non-null    datetime64[ns]\n",
            " 2   HOSPI_CODE_UCD  525 non-null    int64         \n",
            " 3   LIT_HC          525 non-null    float64       \n",
            " 4   LIT_HP          525 non-null    float64       \n",
            " 5   MONTH           525 non-null    int64         \n",
            " 6   N_UFS           525 non-null    float64       \n",
            " 7   PN_MEDICAL      525 non-null    float64       \n",
            " 8   POPULATION      525 non-null    float64       \n",
            " 9   P_MEDICAL       525 non-null    float64       \n",
            " 10  QUANTITY        525 non-null    float64       \n",
            " 11  QUANTITY_MA     525 non-null    float64       \n",
            " 12  SEJ_MCO         525 non-null    float64       \n",
            " 13  SEJ_PSY         525 non-null    float64       \n",
            " 14  SEJ_SSR         525 non-null    float64       \n",
            " 15  WEEK            525 non-null    int64         \n",
            " 16  YEAR            525 non-null    int64         \n",
            " 17  CLUSTER         525 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(11), int64(6)\n",
            "memory usage: 74.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_h3.info()"
      ],
      "metadata": {
        "id": "UCFN6kgrZEAb",
        "outputId": "75f22e26-c5e8-4e60-ee01-02e6b861e884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525 entries, 0 to 524\n",
            "Data columns (total 20 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   CODE_ATC        525 non-null    int64         \n",
            " 1   DATE            525 non-null    datetime64[ns]\n",
            " 2   HOSPI_CODE_UCD  525 non-null    int64         \n",
            " 3   LIT_HC          525 non-null    float64       \n",
            " 4   LIT_HP          525 non-null    float64       \n",
            " 5   MONTH           525 non-null    int64         \n",
            " 6   N_UFS           525 non-null    float64       \n",
            " 7   PN_MEDICAL      525 non-null    float64       \n",
            " 8   POPULATION      525 non-null    float64       \n",
            " 9   P_MEDICAL       525 non-null    float64       \n",
            " 10  QUANTITY        525 non-null    float64       \n",
            " 11  QUANTITY_MA     525 non-null    float64       \n",
            " 12  SEJ_HAD         525 non-null    float64       \n",
            " 13  SEJ_MCO         525 non-null    float64       \n",
            " 14  SEJ_PSY         525 non-null    float64       \n",
            " 15  SEJ_SLD         525 non-null    float64       \n",
            " 16  SEJ_SSR         525 non-null    float64       \n",
            " 17  WEEK            525 non-null    int64         \n",
            " 18  YEAR            525 non-null    int64         \n",
            " 19  CLUSTER         525 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(13), int64(6)\n",
            "memory usage: 82.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_h4.info()"
      ],
      "metadata": {
        "id": "4q2znIq6ZEJs",
        "outputId": "e9426a57-14ff-4be1-95f7-dfc69052e6fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525 entries, 0 to 524\n",
            "Data columns (total 19 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   CODE_ATC        525 non-null    int64         \n",
            " 1   DATE            525 non-null    datetime64[ns]\n",
            " 2   HOSPI_CODE_UCD  525 non-null    int64         \n",
            " 3   LIT_HC          525 non-null    float64       \n",
            " 4   LIT_HP          525 non-null    float64       \n",
            " 5   MONTH           525 non-null    int64         \n",
            " 6   N_UFS           525 non-null    float64       \n",
            " 7   PN_MEDICAL      525 non-null    float64       \n",
            " 8   POPULATION      525 non-null    float64       \n",
            " 9   P_MEDICAL       525 non-null    float64       \n",
            " 10  QUANTITY        525 non-null    float64       \n",
            " 11  QUANTITY_MA     525 non-null    float64       \n",
            " 12  SEJ_MCO         525 non-null    float64       \n",
            " 13  SEJ_PSY         525 non-null    float64       \n",
            " 14  SEJ_SLD         525 non-null    float64       \n",
            " 15  SEJ_SSR         525 non-null    float64       \n",
            " 16  WEEK            525 non-null    int64         \n",
            " 17  YEAR            525 non-null    int64         \n",
            " 18  CLUSTER         525 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(12), int64(6)\n",
            "memory usage: 78.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 - New database composition based on clusters"
      ],
      "metadata": {
        "id": "S8IompnZd1gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_h1_cluster_0 = df_h1[df_h1['CLUSTER'] == 0].copy()\n",
        "df_h1_cluster_1 = df_h1[df_h1['CLUSTER'] == 1].copy()\n",
        "df_h1_cluster_2 = df_h1[df_h1['CLUSTER'] == 2].copy()\n",
        "df_h1_cluster_3 = df_h1[df_h1['CLUSTER'] == 3].copy()"
      ],
      "metadata": {
        "id": "r3PuZvaod6f2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_h2_cluster_0 = df_h2[df_h2['CLUSTER'] == 0].copy()\n",
        "df_h2_cluster_1 = df_h2[df_h2['CLUSTER'] == 1].copy()\n",
        "df_h2_cluster_2 = df_h2[df_h2['CLUSTER'] == 2].copy()\n",
        "df_h2_cluster_3 = df_h2[df_h2['CLUSTER'] == 3].copy()"
      ],
      "metadata": {
        "id": "XyOiO088ekBm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_h3_cluster_0 = df_h3[df_h3['CLUSTER'] == 0].copy()\n",
        "df_h3_cluster_1 = df_h3[df_h3['CLUSTER'] == 1].copy()\n",
        "df_h3_cluster_2 = df_h3[df_h3['CLUSTER'] == 2].copy()\n",
        "df_h3_cluster_3 = df_h3[df_h3['CLUSTER'] == 3].copy()"
      ],
      "metadata": {
        "id": "jViIPc70ekVu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_h4_cluster_0 = df_h4[df_h4['CLUSTER'] == 0].copy()\n",
        "df_h4_cluster_1 = df_h4[df_h4['CLUSTER'] == 1].copy()\n",
        "df_h4_cluster_2 = df_h4[df_h4['CLUSTER'] == 2].copy()\n",
        "df_h4_cluster_3 = df_h4[df_h4['CLUSTER'] == 3].copy()"
      ],
      "metadata": {
        "id": "Ot5QyRR_ekpg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 - Baseline score, Test 1"
      ],
      "metadata": {
        "id": "ZSdBPwLcX1tO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_1_baseline(df, medicine, df_scores, hospital = '-', unified = False):\n",
        "\n",
        "  df = df.fillna(0)\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  X = df[df['HOSPI_CODE_UCD'] == medicine].drop(['QUANTITY', 'DATE', 'WEEK', 'CLUSTER'], axis=1).copy().values\n",
        "  X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "  y = df[df['HOSPI_CODE_UCD'] == medicine]['QUANTITY'].copy().values\n",
        "\n",
        "  if unified:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.35,\n",
        "                                                        random_state=42,\n",
        "                                                        shuffle = True,\n",
        "                                                        stratify=y)\n",
        "\n",
        "  else:\n",
        "    X_train = X_scaled\n",
        "    X_test = X_scaled\n",
        "    y_train = y\n",
        "    y_test = y\n",
        "\n",
        "  # Define the parameter distributions for RandomizedSearchCV\n",
        "  param_distributions = {\n",
        "      'max_depth': np.arange(2, 31, 2),\n",
        "      'n_estimators': np.arange(2, 201, 2),\n",
        "      'max_features': ['sqrt', 'log2'],\n",
        "      'min_samples_split': np.arange(2, 11, 2),\n",
        "      'min_samples_leaf': np.arange(2, 5, 1)\n",
        "  }\n",
        "\n",
        "  # Create the RandomizedSearchCV object\n",
        "  randomized_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                                          param_distributions=param_distributions,\n",
        "                                          n_iter=100,\n",
        "                                          cv=5,\n",
        "                                          random_state=42)\n",
        "\n",
        "  # Fit the RandomizedSearchCV object to the data\n",
        "  randomized_search.fit(X_train, y_train)\n",
        "\n",
        "  # Get the best estimator\n",
        "  best_estimator = randomized_search.best_estimator_\n",
        "\n",
        "  # Make predictions using the best estimator\n",
        "  y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "  # Calculate R^2 score\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  # Calculate MAE\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "  # Calculate MAPE\n",
        "  mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "  # Calculate RMSE\n",
        "  rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "  # Print the best parameters, best score, and evaluation metrics\n",
        "  print('Medicine:' + str(medicine))\n",
        "  print('Best Parameters:', randomized_search.best_params_)\n",
        "  print('Best Score:', randomized_search.best_score_)\n",
        "  print('R^2 Score:', round(r2, 3))\n",
        "  print('MAE:', round(mae, 3))\n",
        "  print('MAPE:', round(mape, 3))\n",
        "  print('RMSE:', round(rmse, 3))\n",
        "  print()\n",
        "\n",
        "\n",
        "  # Create the new row as a DataFrame\n",
        "  new_row = pd.DataFrame({'ID_SITE_RATTACHE': [hospital],\n",
        "                          'HOSPI_CODE_UCD': ['CODE_UCD_'+str(medicine)],\n",
        "                          'R2': [r2],\n",
        "                          'RMSE': [rmse],\n",
        "                          'MAE': [mae],\n",
        "                          'MAPE': [mape]})\n",
        "\n",
        "  # Append the new row to the DataFrame\n",
        "  df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
        "\n",
        "  # Return the updated DataFrame\n",
        "  return df_scores\n"
      ],
      "metadata": {
        "id": "6Ujw8j04X53l"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h1 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "for medicine in df_h1.HOSPI_CODE_UCD.unique():\n",
        "\n",
        "  df_prediction_scores_h1 = test_1_baseline(df_h1, medicine, df_prediction_scores_h1, hospital = 'HOSPI_1', unified = False)\n",
        "\n",
        "df_prediction_scores_h1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y_J-hoeanRP",
        "outputId": "7529a2a8-f9c4-47f7-d031-d8746c3421c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medicine:3400890837149\n",
            "Best Parameters: {'n_estimators': 56, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 8}\n",
            "Best Score: -0.9345859727694268\n",
            "R^2 Score: 0.551\n",
            "MAE: 96.027\n",
            "MAPE: 0.035\n",
            "RMSE: 144.669\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h2 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "for medicine in df_h2.HOSPI_CODE_UCD.unique():\n",
        "\n",
        "  df_prediction_scores_h2 = test_1_baseline(df_h2, medicine, df_prediction_scores_h2, hospital = 'HOSPI_2', unified = False)\n",
        "\n",
        "df_prediction_scores_h2"
      ],
      "metadata": {
        "id": "K6jeu0cSdX4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h3 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "for medicine in df_h3.HOSPI_CODE_UCD.unique():\n",
        "\n",
        "  df_prediction_scores_h3 = test_1_baseline(df_h3, medicine, df_prediction_scores_h3, hospital = 'HOSPI_3', unified = False)\n",
        "\n",
        "df_prediction_scores_h3"
      ],
      "metadata": {
        "id": "vuGcIV39dhLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h4 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "for medicine in df_h4.HOSPI_CODE_UCD.unique():\n",
        "\n",
        "  df_prediction_scores_h4 = test_1_baseline(df_h4, medicine, df_prediction_scores_h4, hospital = 'HOSPI_4', unified = False)\n",
        "\n",
        "df_prediction_scores_h4"
      ],
      "metadata": {
        "id": "vUKpMMjrdhSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_unified = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_unified = pd.concat([df_h1,df_h2,df_h3, df_h4])\n",
        "\n",
        "for medicine in df_unified.HOSPI_CODE_UCD.unique():\n",
        "\n",
        "  df_prediction_scores_unified = test_1_baseline(df_unified, medicine, df_prediction_scores_unified, hospital = '-', unified = True)\n",
        "\n",
        "df_prediction_scores_unified.to_csv('df_prediction_scores_unified.csv')"
      ],
      "metadata": {
        "id": "-TmIooNMkCRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 - Clustering score, Test 2"
      ],
      "metadata": {
        "id": "ZFFuePTEjeHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_2_clustering(df, df_scores, hospital = '-', unified = False):\n",
        "\n",
        "  df = df.fillna(0)\n",
        "  cluster = df.CLUSTER.unique()[0]\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  X = df.drop(['QUANTITY', 'DATE', 'WEEK', 'CLUSTER'], axis=1).copy().values\n",
        "  y = df['QUANTITY'].copy().values\n",
        "  if unified:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                        test_size=0.2,\n",
        "                                                        random_state=42,\n",
        "                                                        shuffle = True,\n",
        "                                                        stratify=y)\n",
        "  else:\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "\n",
        "    X_test = X\n",
        "    y_test = y\n",
        "\n",
        "\n",
        "  # Define the parameter distributions for RandomizedSearchCV\n",
        "  param_distributions = {\n",
        "      'max_depth': np.arange(2, 31, 2),\n",
        "      'n_estimators': np.arange(2, 201, 2),\n",
        "      'max_features': ['sqrt', 'log2'],\n",
        "      'min_samples_split': np.arange(2, 11, 2),\n",
        "      'min_samples_leaf': np.arange(2, 5, 1)\n",
        "  }\n",
        "\n",
        "  # Create the RandomizedSearchCV object\n",
        "  randomized_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
        "                                          param_distributions=param_distributions,\n",
        "                                          n_iter=100,\n",
        "                                          cv=5,\n",
        "                                          random_state=42)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "  # Fit the RandomizedSearchCV object to the data\n",
        "  randomized_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # Get the best estimator\n",
        "  best_estimator = randomized_search.best_estimator_\n",
        "\n",
        "  print(f'Cluster: {cluster}')\n",
        "  print('Best Parameters:', randomized_search.best_params_)\n",
        "  print('Best Score:', randomized_search.best_score_)\n",
        "  print(f'Data in train: {len(X_train)}')\n",
        "\n",
        "  df_test = pd.DataFrame(X_test, columns = df.drop(['QUANTITY', 'DATE', 'WEEK', 'CLUSTER'], axis=1).copy().columns)\n",
        "  df_test['QUANTITY'] = y_test\n",
        "\n",
        "  for medicine in df_test.HOSPI_CODE_UCD.unique():\n",
        "    X_test_medicine = df_test[df_test['HOSPI_CODE_UCD'] == medicine].drop(['QUANTITY'], axis=1).copy().values\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test_medicine)\n",
        "\n",
        "    y_test_medicine = df_test[df_test['HOSPI_CODE_UCD'] == medicine]['QUANTITY'].copy().values\n",
        "\n",
        "    print()\n",
        "    print(f'Data in test: {len(X_test_medicine)}')\n",
        "    # Make predictions using the best estimator\n",
        "    y_pred = best_estimator.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate R^2 score\n",
        "    r2 = r2_score(y_test_medicine, y_pred)\n",
        "\n",
        "    # Calculate MAE\n",
        "    mae = mean_absolute_error(y_test_medicine, y_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    mape = mean_absolute_percentage_error(y_test_medicine, y_pred)\n",
        "\n",
        "    # Calculate RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_medicine, y_pred))\n",
        "\n",
        "    # Print the best parameters, best score, and evaluation metrics\n",
        "    print('Medicine:' + str(medicine))\n",
        "    print('Medicines in cluster: ')\n",
        "    print('R^2 Score:', round(r2, 3))\n",
        "    print('MAE:', round(mae, 3))\n",
        "    print('MAPE:', round(mape, 3))\n",
        "    print('RMSE:', round(rmse, 3))\n",
        "    print()\n",
        "\n",
        "\n",
        "    # Create the new row as a DataFrame\n",
        "    new_row = pd.DataFrame({'ID_SITE_RATTACHE': [hospital],\n",
        "                            'CLUSTER': [cluster],\n",
        "                            'HOSPI_CODE_UCD': ['CODE_UCD_'+str(medicine)],\n",
        "                            'R2': [r2],\n",
        "                            'RMSE': [rmse],\n",
        "                            'MAE': [mae],\n",
        "                            'MAPE': [mape]})\n",
        "\n",
        "    # Append the new row to the DataFrame\n",
        "    df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
        "\n",
        "  # Return the updated DataFrame\n",
        "  return df_scores\n"
      ],
      "metadata": {
        "id": "svktlbzP3uig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hospital 1 - Cluster 0"
      ],
      "metadata": {
        "id": "ndhV9Zkb2Wt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h1_cluster_0 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h1_cluster_0 = test_2_clustering(df_h1_cluster_0, df_prediction_scores_h1_cluster_0, hospital = 'HOSPI_1')\n",
        "\n",
        "df_prediction_scores_h1_cluster_0"
      ],
      "metadata": {
        "id": "H1wF3tWtjcKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h1_cluster_1 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h1_cluster_1 = test_2_clustering(df_h1_cluster_1, df_prediction_scores_h1_cluster_1, hospital = 'HOSPI_1')\n",
        "\n",
        "df_prediction_scores_h1_cluster_1"
      ],
      "metadata": {
        "id": "HPRGAt6M6BGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h1_cluster_2 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h1_cluster_2 = test_2_clustering(df_h1_cluster_2, df_prediction_scores_h1_cluster_2, hospital = 'HOSPI_1')\n",
        "\n",
        "df_prediction_scores_h1_cluster_2"
      ],
      "metadata": {
        "id": "K5gJfe7b7nCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h1_cluster_3 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h1_cluster_3 = test_2_clustering(df_h1_cluster_3, df_prediction_scores_h1_cluster_3, hospital = 'HOSPI_1')\n",
        "\n",
        "df_prediction_scores_h1_cluster_3"
      ],
      "metadata": {
        "id": "kNmvnL0j7nrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_prediction_scores_h1_cluster_0,\n",
        "           df_prediction_scores_h1_cluster_1,\n",
        "           df_prediction_scores_h1_cluster_2,\n",
        "           df_prediction_scores_h1_cluster_3])"
      ],
      "metadata": {
        "id": "p1uKOzo370Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h2_cluster_0 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h2_cluster_0 = test_2_clustering(df_h2_cluster_0, df_prediction_scores_h2_cluster_0, hospital = 'HOSPI_2')\n",
        "\n",
        "df_prediction_scores_h2_cluster_0"
      ],
      "metadata": {
        "id": "MNhKmt8AAVxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h2_cluster_1 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h2_cluster_1 = test_2_clustering(df_h2_cluster_1, df_prediction_scores_h2_cluster_1, hospital = 'HOSPI_2')\n",
        "\n",
        "df_prediction_scores_h2_cluster_1"
      ],
      "metadata": {
        "id": "2AlyvidMAWya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h2_cluster_2 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h2_cluster_2 = test_2_clustering(df_h2_cluster_2, df_prediction_scores_h2_cluster_2, hospital = 'HOSPI_2')\n",
        "\n",
        "df_prediction_scores_h2_cluster_2"
      ],
      "metadata": {
        "id": "G-xATFM2AXB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_h2_cluster_3 = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_h2_cluster_3 = test_2_clustering(df_h2_cluster_3, df_prediction_scores_h2_cluster_3, hospital = 'HOSPI_2')\n",
        "\n",
        "df_prediction_scores_h2_cluster_3"
      ],
      "metadata": {
        "id": "98OiRJyEAXwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_prediction_scores_h2_cluster_0,\n",
        "           df_prediction_scores_h2_cluster_1,\n",
        "           df_prediction_scores_h2_cluster_2,\n",
        "           df_prediction_scores_h2_cluster_3])"
      ],
      "metadata": {
        "id": "fp6iHQzbAZhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction_scores_unified_cluster = pd.DataFrame(columns=['ID_SITE_RATTACHE', 'HOSPI_CODE_UCD', 'R2', 'RMSE', 'MAE', 'MAPE'])\n",
        "\n",
        "df_prediction_scores_unified_cluster = test_2_clustering(pd.concat(df_h1,\n",
        "                                                                   df_h2,\n",
        "                                                                   df_h3,\n",
        "                                                                   df_h4), df_prediction_scores_unified_cluster, hospital = '-', unified = True)\n",
        "\n",
        "df_prediction_scores_unified_cluster"
      ],
      "metadata": {
        "id": "AbuVYPL8Fjst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}